#!/usr/bin/env python3
"""æ‰¹é‡æ‰§è¡Œæ™ºèƒ½åˆçº¦å®¡è®¡"""

import os
import subprocess
import csv
from pathlib import Path
from datetime import datetime

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = Path('/home/zhuwei/PycharmProjects/MyLLM')
BENCHMARK_DIR = PROJECT_ROOT / 'evaluation' / 'benchmark' / 'contracts'

# é…ç½®è®¾ç½®
CONFIG_NAME = "SmartContractCKD"  # ä½¿ç”¨ myConfig é…ç½®

# æ³¨æ„: OPENAI_API_KEY éœ€è¦åœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­é…ç½®


def audit_contract(sol_file: Path, config: str = "myConfig"):
    """å®¡è®¡å•ä¸ªåˆçº¦"""
    # è¯»å–åˆçº¦å†…å®¹
    with open(sol_file, 'r', encoding='utf-8') as f:
        contract_content = f.read()

    # æ£€æŸ¥æ˜¯å¦è®¾ç½®äº†å®éªŒé…ç½®ï¼ˆä»ç¯å¢ƒå˜é‡è·å–å®éªŒIDï¼‰
    experiment_id = os.environ.get('EXPERIMENT_ID', '')
    
    # ç”Ÿæˆé¡¹ç›®åç§°ï¼ˆä½¿ç”¨ç›¸å¯¹äºBENCHMARK_DIRçš„è·¯å¾„ä½œä¸ºæ ‡è¯†ï¼‰
    relative_to_benchmark = sol_file.relative_to(BENCHMARK_DIR)
    # å°†è·¯å¾„ä¸­çš„ / æ›¿æ¢ä¸º _ ä½œä¸ºé¡¹ç›®å
    path_parts = str(relative_to_benchmark.parent).replace('/', '_').replace('.', '')
    filename = sol_file.stem
    
    # å¦‚æœæœ‰å®éªŒIDï¼Œæ·»åŠ åˆ°é¡¹ç›®åç§°å‰ç¼€
    if experiment_id:
        project_name = f"{experiment_id}_{path_parts}_{filename}" if path_parts else f"{experiment_id}_{filename}"
    else:
        project_name = f"ContractAudit_{path_parts}_{filename}" if path_parts else f"ContractAudit_{filename}"

    # ä½¿ç”¨ç»å¯¹è·¯å¾„ä¼ é€’ç»™ --sol å‚æ•°ï¼ˆç¡®ä¿ä»£ç èƒ½æ­£ç¡®æ‰¾åˆ°æ–‡ä»¶ï¼‰
    absolute_sol_path = sol_file.resolve()

    # æ„å»ºå‘½ä»¤ (--sol å‚æ•°ä½¿ç”¨ç»å¯¹è·¯å¾„)
    command = [
        "python", "run.py",
        "--org", config,
        "--config", config,
        "--task", contract_content,
        "--name", project_name,
        "--sol", str(absolute_sol_path),  # ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿èƒ½æ­£ç¡®å®šä½æ–‡ä»¶
        "--model", "GPT_4_O_MINI"  # ä½¿ç”¨ Claude Sonnet 4.5 é¿å… Gemini API é”™è¯¯
    ]

    print(f"ğŸ” Auditing: {sol_file.relative_to(PROJECT_ROOT)}")
    print(f"   Config: {config}")
    print(f"   Experiment: {experiment_id if experiment_id else 'None'}")
    print(f"   Project: {project_name}")
    print(f"   Sol Path: {absolute_sol_path}")
    print("-" * 80)

    try:
        # æ•è·è¾“å‡ºï¼Œä¸æ˜¾ç¤ºåœ¨ç»ˆç«¯
        result = subprocess.run(
            command,
            cwd=PROJECT_ROOT,
            check=True,
            capture_output=True,  # æ•è·è¾“å‡ºï¼Œä¸æ˜¾ç¤ºåœ¨ç»ˆç«¯
            text=True,
            timeout=None  # æ— è¶…æ—¶é™åˆ¶
        )
        print("-" * 80)
        print(f"âœ… Success: {project_name}\n")
        return True
    except subprocess.CalledProcessError as e:
        print("-" * 80)
        print(f"âŒ Error: {project_name}")
        print(f"   Exit Code: {e.returncode}")
        print(f"   Error Output (last 1000 chars):")
        if e.stderr:
            print(f"   STDERR: {e.stderr[-1000:]}")
        if e.stdout:
            print(f"   STDOUT: {e.stdout[-1000:]}")
        print()
        return False


def collect_results_to_csv(output_csv: Path):
    """æ”¶é›†æ‰€æœ‰å®¡è®¡ç»“æœåˆ°ç»Ÿä¸€çš„CSVæ–‡ä»¶"""
    warehouse_dir = PROJECT_ROOT / 'WareHouse'
    all_results = []
    
    # éå†æ‰€æœ‰é¡¹ç›®ç›®å½•
    for project_dir in warehouse_dir.iterdir():
        if not project_dir.is_dir():
            continue
        
        # æŸ¥æ‰¾binary_classification_result.csv
        csv_file = project_dir / 'binary_classification_result.csv'
        if csv_file.exists():
            try:
                with open(csv_file, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        all_results.append({
                            'File Name': row['File Name'],
                            'Has Vulnerability': row['Has Vulnerability']
                        })
            except Exception as e:
                print(f"âš ï¸  Error reading {csv_file}: {e}")
    
    # å†™å…¥æ±‡æ€»CSV
    if all_results:
        with open(output_csv, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['File Name', 'Has Vulnerability'])
            writer.writeheader()
            writer.writerows(all_results)
        print(f"\n{'=' * 80}")
        print(f"ğŸ“„ Results exported to: {output_csv}")
        print(f"   Total records: {len(all_results)}")
        print(f"{'=' * 80}")
    else:
        print("\nâš ï¸  No results found to export.")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print(f"ğŸš€ æ™ºèƒ½åˆçº¦æ‰¹é‡å®¡è®¡ç³»ç»Ÿ")
    print(f"ğŸ“‹ é…ç½®: {CONFIG_NAME}")
    print(f"ğŸ“‚ æ•°æ®é›†: {BENCHMARK_DIR.relative_to(PROJECT_ROOT)}")
    print("=" * 80)
    
    # ç»Ÿè®¡
    total = 0
    success = 0
    failed = 0

    # é€’å½’éå†æ‰€æœ‰.solæ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰
    all_sol_files = list(BENCHMARK_DIR.rglob('*.sol'))
    
    print(f"\nğŸ“Š Found {len(all_sol_files)} .sol files in total")
    print("=" * 80)

    for sol_file in sorted(all_sol_files):
        # è·å–ç›¸å¯¹è·¯å¾„ç”¨äºæ˜¾ç¤º
        relative_path = sol_file.relative_to(BENCHMARK_DIR)
        
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ Processing: {relative_path}")
        print(f"{'=' * 60}")
        
        total += 1
        # æ˜¾å¼ä½¿ç”¨ CONFIG_NAME
        if audit_contract(sol_file, config=CONFIG_NAME):
            success += 1
        else:
            failed += 1

    # è¾“å‡ºç»Ÿè®¡
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š Summary")
    print(f"{'=' * 60}")
    print(f"Total:   {total}")
    print(f"Success: {success} ({success / total * 100:.1f}%)")
    print(f"Failed:  {failed} ({failed / total * 100:.1f}%)")
    
    # æ±‡æ€»æ‰€æœ‰ç»“æœåˆ°CSV
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_csv = PROJECT_ROOT / 'results' / f'vulnerability_detection_results_{timestamp}.csv'
    output_csv.parent.mkdir(exist_ok=True)
    collect_results_to_csv(output_csv)


if __name__ == "__main__":
    main()